{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "028aae3e-6fed-4031-8503-298f6f88dc1e",
   "metadata": {},
   "source": [
    "UFORMER: A UNET BASED DILATED COMPLEX & REAL DUAL-PATH CONFORMER NETWORK FOR SIMULTANEOUS SPEECH ENHANCEMENT AND DEREVERBERATION  \n",
    "https://arxiv.org/pdf/2111.06015.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ee4898c-ccf4-45ab-b4ba-2939ca4a7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f558c45-2c93-444b-bbdc-147d88edbb70",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Encoder-Decoder Attention  \n",
    "\n",
    "$$ \\mathbf{G}_i = \\sigma(\\mathbf{W}_i^E * \\mathbf{E}_i + \\mathbf{W}_i^D * \\mathbf{D}_i)\\tag{10}$$  \n",
    "\n",
    "$$ \\hat{\\mathbf{D}}_i = \\sigma(\\mathbf{W}^A_i * \\mathbf{G}_i) \\odot \\mathbf{D}_i  \\tag{11} $$\n",
    "\n",
    "이전 레이어 출력과 skip connection을 각각 conv2d 돌린걸 합친걸 sigmoid 때려서 (10) 생성   \n",
    "(10) 에다가 conv2d 때리고 sigmoid 때린걸 마스크로 해서 이전 레이어의 출력과 곱해줌.      \n",
    "이거를 이전 레이어 출력과 concat해서 다음 레이어에 보내줌      \n",
    "\n",
    "=>  \n",
    "\n",
    "3개의 conv2d가 필요하다.  \n",
    "\n",
    "```\n",
    "For encoder-decoder attention, the kernel size of three Conv2ds is (2, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14b6517f-49e2-470f-bddb-ebbde2d2c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderAttention(nn.Module):\n",
    "    def __init__(self,channels) -> None :\n",
    "        super(EncoderDecoderAttention,self).__init__()\n",
    "        \n",
    "        # Encoder Kernel  \n",
    "        self.w_e = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=(2,3),stride=1, padding=\"same\", dilation=1)\n",
    "        # Decoder Kernel  \n",
    "        self.w_d = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=(2,3),stride=1, padding=\"same\", dilation=1)\n",
    "        # Attention Kernel  \n",
    "        self.w_a = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=(2,3),stride=1, padding=\"same\", dilation=1)\n",
    "        \n",
    "        self.sigma = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, d:Tensor, e:Tensor) -> Tensor:\n",
    "        ## (10) extracting high dimensional feature\n",
    "        g = self.sigma(self.w_e(e) + self.w_d(d))\n",
    "        \n",
    "        ## (11) multipling attention masking\n",
    "        d_hat = torch.mul(self.sigma(self.w_a(g)),d)\n",
    "        return d_hat\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67231df1-ee8f-4516-862c-9d8be0231e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "B = 2\n",
    "C = 3\n",
    "T = 4\n",
    "F = 5\n",
    "e = torch.rand(B,C,T,F)\n",
    "d = torch.rand(B,C,T,F)\n",
    "m = EncoderDecoderAttention(C)\n",
    "\n",
    "y = m(d,e)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b9bdf-ba71-4392-971d-04986657b28d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dilated Conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2e579-903d-44f6-a970-f24cd08c529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialatedConformer(nn.Module):\n",
    "    def __init__(self) -> None :\n",
    "        super(DialatedConformer,self,dim_in).__init__()\n",
    "        \n",
    "        dim_emb_1 = 1024\n",
    "        num_head_1 = 8\n",
    "        self.FF1 = nn.Linear(dim_in,dim_emb_1)\n",
    "        self.TA = nn.MultiheadAttention(\n",
    "            embed_dim=dim_emb_1,\n",
    "            num_heads = num_head_1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.FA = nn.MultiheadAttention(\n",
    "            embed_dim=dim_emb_1,\n",
    "            num_heads = num_head_1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.DC\n",
    "        self.FF2\n",
    "        self.LN\n",
    "    def forward(self, x:Tensor) -> Tensor : \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
